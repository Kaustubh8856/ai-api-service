# üöÄ AI API Service  

A **production-ready AI-powered REST API service** built with **FastAPI** and **Python**, providing endpoints for various AI tasks including **text generation, translation, summarization, and code generation**.  

---

## ‚ú® Features  
- **Text Generation**: Generate human-like text using advanced AI models  
- **Translation**: Translate text between multiple languages  
- **Summarization**: Condense long texts into concise summaries  
- **Code Generation**: Generate code snippets based on natural language instructions  
- **Multiple AI Providers**: Supports **Groq API** with **Hugging Face fallback**  
- **RESTful API**: Clean, well-documented endpoints  
- **FastAPI Backend**: High-performance asynchronous API  
- **React Frontend**: Modern web interface for testing the API  
- **Production Ready**: Error handling, logging, and health checks  

---

## üõ†Ô∏è Tech Stack  

**Backend**  
- Python 3.11+  
- FastAPI  
- Pydantic  
- Uvicorn  
- python-dotenv  

**AI Providers**  
- Groq API (Primary) ‚Üí *Llama 3.1, Mixtral models*  
- Hugging Face Inference API (Fallback)  

**Frontend**  
- React  
- Axios for API calls  
- Modern CSS styling  

---

## üì¶ Installation  

### Prerequisites  
- Python 3.11 or higher  
- Node.js 16+ (for frontend)  
- Groq API account (free at [console.groq.com](https://console.groq.com))  

### 1. Clone the Repository  
```bash
git clone https://github.com/Kaustubh8856/ai-api-service
cd ai-api-service
```

### 2. Set Up Backend  
```bash
# Create virtual environment
python -m venv venv  

# Activate virtual environment
# On Windows:
venv\Scripts\activate  
# On macOS/Linux:
source venv/bin/activate  

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure Environment Variables  
Create a **.env** file in the root directory:  

```env
# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant  

# Hugging Face Configuration (Optional Fallback)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_MODEL=microsoft/DialoGPT-medium  

# App Configuration
APP_ENV=development
LOG_LEVEL=INFO
```

### 4. Set Up Frontend  
```bash
# Navigate to frontend directory
cd frontend  

# Install dependencies
npm install  

# Return to root directory
cd ..
```

---

## üèÉ Running the Application  

### Start Backend Server  
```bash
# Make sure virtual environment is activated
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Start Frontend Development Server  
```bash
# Open new terminal window/tab
cd frontend
npm start
```

### Access the Application  
- **Backend API**: [http://localhost:8000](http://localhost:8000)  
- **API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs)  
- **Frontend Application**: [http://localhost:3000](http://localhost:3000)  

---

## üìö API Endpoints  

### Core Endpoints  
- `GET /` ‚Üí Root endpoint with API information  
- `GET /health` ‚Üí Health check endpoint  
- `GET /info` ‚Üí API configuration information  

### AI Endpoints  
- `POST /ai/generate` ‚Üí Generate text from prompt  
- `POST /ai/translate` ‚Üí Translate text between languages  
- `POST /ai/summarize` ‚Üí Summarize long text  
- `POST /ai/generate-code` ‚Üí Generate code from instructions  
- `POST /ai/chat` ‚Üí Chat completion endpoint  
- `GET /ai/models` ‚Üí List available AI models  
- `GET /ai/provider` ‚Üí Get current AI provider information  
- `GET /ai/status` ‚Üí Service status information  

---

## üéØ Usage Examples  

### Text Generation  
```bash
curl -X POST "http://localhost:8000/ai/generate"   -H "Content-Type: application/json"   -d '{
    "prompt": "Explain quantum computing in simple terms",
    "max_tokens": 150,
    "temperature": 0.7
  }'
```

### Translation  
```bash
curl -X POST "http://localhost:8000/ai/translate"   -H "Content-Type: application/json"   -d '{
    "text": "Hello, how are you today?",
    "target_language": "Spanish",
    "source_language": "English"
  }'
```

### Code Generation  
```bash
curl -X POST "http://localhost:8000/ai/generate-code"   -H "Content-Type: application/json"   -d '{
    "instruction": "Create a function that checks if a number is prime",
    "language": "python",
    "max_tokens": 100
  }'
```

---

## üèóÔ∏è Project Structure  

```
ai-api-service/
‚îú‚îÄ‚îÄ app/                    # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ routers/            # API route handlers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai.py           # AI endpoints
‚îÇ   ‚îú‚îÄ‚îÄ services/           # AI service integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ groq_service.py         # Groq API service
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ huggingface_service.py  # Hugging Face service
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # FastAPI application
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py         # Package initialization
‚îú‚îÄ‚îÄ frontend/               # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/     # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # API service layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.js          # Main App component
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.css         # Styles
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ public/
‚îú‚îÄ‚îÄ .env                    # Environment variables
‚îú‚îÄ‚îÄ .gitignore              # Git ignore rules
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îî‚îÄ‚îÄ README.md               # Documentation
```

---

## üîß Configuration  

### Environment Variables  
- **GROQ_API_KEY**: Your Groq API key (**required**)  
- **GROQ_MODEL**: Groq model to use *(default: `llama-3.1-8b-instant`)*  
- **HUGGINGFACE_API_KEY**: Hugging Face API key *(optional fallback)*  
- **HUGGINGFACE_MODEL**: Hugging Face model *(default: `microsoft/DialoGPT-medium`)*  
- **APP_ENV**: Application environment *(development/production)*  
- **LOG_LEVEL**: Logging level *(INFO/DEBUG/ERROR)*  

### Available Models  
- **Groq Models**:  
  - `llama-3.1-8b-instant`  
  - `llama-3.1-70b-versatile`  
  - `mixtral-8x7b-32768`  
  - `gemma-7b-it`  

- **Hugging Face Models**:  
  - `microsoft/DialoGPT-medium`  
  - `facebook/bart-large-cnn`  
  - `google/t5-v1_1-base`  

---

## üêõ Troubleshooting  

- **ModuleNotFoundError**: Ensure virtual environment is activated and dependencies are installed  
- **API Key Errors**: Verify your Groq API key in the `.env` file  
- **CORS Errors**: Ensure frontend and backend are running on correct ports  
- **Model Not Available**: Check if the specified model exists in your API provider  

---

## ü§ù Contributing  

1. Fork the repository  
2. Create a feature branch  
   ```bash
   git checkout -b feature/amazing-feature
   ```  
3. Commit your changes  
   ```bash
   git commit -m 'Add amazing feature'
   ```  
4. Push to the branch  
   ```bash
   git push origin feature/amazing-feature
   ```  
5. Open a Pull Request  

---

## üìÑ License  
This project is licensed under the **MIT License** ‚Äì see the [LICENSE](LICENSE) file for details.  

---

## üôè Acknowledgments  
- [FastAPI](https://fastapi.tiangolo.com/) ‚Äì Excellent web framework  
- [Groq](https://console.groq.com/) ‚Äì Fast AI inference provider  
- [Hugging Face](https://huggingface.co/) ‚Äì Open-source AI models  
- [React](https://react.dev/) ‚Äì Modern frontend framework  

---

> ‚ö†Ô∏è **Note**: This project is for **demonstration and educational purposes**. Ensure you comply with the **terms of service** of the AI providers you use.  
